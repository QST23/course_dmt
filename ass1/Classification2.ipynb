{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('Datasets/cleaned_data.csv')\n",
    "\n",
    "# Round the mood column to nearest integer\n",
    "df['mood'] = df['mood'].round()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract year, month, day, hour, and minute as separate columns\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"day\"] = df[\"date\"].dt.day\n",
    "\n",
    "# Perform one-hot encoding one the persons\n",
    "one_hot_df = pd.get_dummies(df['id'])\n",
    "\n",
    "# Concatenate the one-hot encoded columns to the original DataFrame\n",
    "df = pd.concat([df, one_hot_df], axis=1)\n",
    "\n",
    "# Drop the original categorical column\n",
    "df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and target variables\n",
    "X = df.drop([\"date\", \"mood\"], axis=1) # drop the date and target columns\n",
    "y = df[\"mood\"]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features using StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Encode target variable using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Reshape input data to fit RNN input shape\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 7s 94ms/step - loss: 2.2726 - accuracy: 0.4722 - val_loss: 2.2234 - val_accuracy: 0.5594\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 2.1512 - accuracy: 0.5307 - val_loss: 1.9889 - val_accuracy: 0.5632\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 1.7416 - accuracy: 0.5287 - val_loss: 1.3219 - val_accuracy: 0.5517\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.2233 - accuracy: 0.4981 - val_loss: 1.0811 - val_accuracy: 0.5632\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.0674 - accuracy: 0.5508 - val_loss: 1.0333 - val_accuracy: 0.5441\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.9997 - accuracy: 0.5785 - val_loss: 0.9780 - val_accuracy: 0.5632\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.9211 - accuracy: 0.6169 - val_loss: 0.9210 - val_accuracy: 0.5977\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.8415 - accuracy: 0.6571 - val_loss: 0.8547 - val_accuracy: 0.6322\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.7774 - accuracy: 0.6925 - val_loss: 0.8317 - val_accuracy: 0.6705\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.7380 - accuracy: 0.6916 - val_loss: 0.7988 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.6958 - accuracy: 0.7165 - val_loss: 0.7887 - val_accuracy: 0.6858\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.6570 - accuracy: 0.7375 - val_loss: 0.7798 - val_accuracy: 0.6552\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.6386 - accuracy: 0.7404 - val_loss: 0.7933 - val_accuracy: 0.6858\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.6279 - accuracy: 0.7471 - val_loss: 0.7836 - val_accuracy: 0.6705\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.6094 - accuracy: 0.7423 - val_loss: 0.7937 - val_accuracy: 0.6552\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.6059 - accuracy: 0.7519 - val_loss: 0.7970 - val_accuracy: 0.6590\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.5884 - accuracy: 0.7644 - val_loss: 0.7969 - val_accuracy: 0.6705\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5721 - accuracy: 0.7644 - val_loss: 0.8165 - val_accuracy: 0.6552\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.5663 - accuracy: 0.7557 - val_loss: 0.8297 - val_accuracy: 0.6513\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5578 - accuracy: 0.7701 - val_loss: 0.8236 - val_accuracy: 0.6552\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5522 - accuracy: 0.7797 - val_loss: 0.8246 - val_accuracy: 0.6475\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5370 - accuracy: 0.7768 - val_loss: 0.8250 - val_accuracy: 0.6590\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5161 - accuracy: 0.7778 - val_loss: 0.8256 - val_accuracy: 0.6552\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.5307 - accuracy: 0.7864 - val_loss: 0.8481 - val_accuracy: 0.6322\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5263 - accuracy: 0.7854 - val_loss: 0.8399 - val_accuracy: 0.6590\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5198 - accuracy: 0.7835 - val_loss: 0.8641 - val_accuracy: 0.6322\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4943 - accuracy: 0.8046 - val_loss: 0.8790 - val_accuracy: 0.6705\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5276 - accuracy: 0.7816 - val_loss: 0.8658 - val_accuracy: 0.6360\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.4896 - accuracy: 0.7989 - val_loss: 0.8779 - val_accuracy: 0.6322\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4836 - accuracy: 0.8017 - val_loss: 0.8768 - val_accuracy: 0.6437\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4870 - accuracy: 0.7893 - val_loss: 0.8942 - val_accuracy: 0.6322\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4633 - accuracy: 0.8084 - val_loss: 0.8970 - val_accuracy: 0.6513\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4643 - accuracy: 0.8180 - val_loss: 0.9004 - val_accuracy: 0.6322\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.4486 - accuracy: 0.8228 - val_loss: 0.9176 - val_accuracy: 0.6513\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4453 - accuracy: 0.8209 - val_loss: 0.9390 - val_accuracy: 0.6360\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4502 - accuracy: 0.8132 - val_loss: 0.9438 - val_accuracy: 0.6322\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4387 - accuracy: 0.8161 - val_loss: 0.9476 - val_accuracy: 0.6322\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4492 - accuracy: 0.8065 - val_loss: 0.9474 - val_accuracy: 0.6322\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.4360 - accuracy: 0.8151 - val_loss: 0.9392 - val_accuracy: 0.6437\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4103 - accuracy: 0.8305 - val_loss: 0.9465 - val_accuracy: 0.6513\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.3891 - accuracy: 0.8458 - val_loss: 0.9729 - val_accuracy: 0.6475\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4278 - accuracy: 0.8218 - val_loss: 0.9922 - val_accuracy: 0.6398\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4154 - accuracy: 0.8352 - val_loss: 0.9932 - val_accuracy: 0.6437\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.3965 - accuracy: 0.8333 - val_loss: 1.0142 - val_accuracy: 0.6628\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4105 - accuracy: 0.8333 - val_loss: 1.0142 - val_accuracy: 0.6360\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.3963 - accuracy: 0.8391 - val_loss: 1.0331 - val_accuracy: 0.6513\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.3979 - accuracy: 0.8333 - val_loss: 1.0202 - val_accuracy: 0.6552\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.3690 - accuracy: 0.8381 - val_loss: 1.0573 - val_accuracy: 0.6322\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.3950 - accuracy: 0.8429 - val_loss: 1.0538 - val_accuracy: 0.6513\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.3934 - accuracy: 0.8324 - val_loss: 1.0376 - val_accuracy: 0.6360\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0376 - accuracy: 0.6360\n",
      "Test loss: 1.0375967025756836\n",
      "Test accuracy: 0.6360152959823608\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "lstm_size = 100\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "optimizer = 'adam'\n",
    "eps = 50\n",
    "batch = 64\n",
    "\n",
    "# Define RNN model architecture\n",
    "model = Sequential()    \n",
    "for i in range(num_layers):\n",
    "    model.add(LSTM(units=lstm_size, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "model.add(LSTM(units=lstm_size))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=eps, batch_size=batch, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noahv\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 5s 6ms/step - loss: 2.2589 - accuracy: 0.4713\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.1093 - accuracy: 0.5172\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 1.6123 - accuracy: 0.5172\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 1.2075 - accuracy: 0.5172\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 1.1424 - accuracy: 0.5172\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.5172\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 1.0791 - accuracy: 0.5172\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 1.0499 - accuracy: 0.5330\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 1.0058 - accuracy: 0.5517\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.9688 - accuracy: 0.5819\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.9157 - accuracy: 0.6336\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.8674 - accuracy: 0.6638\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.8091 - accuracy: 0.6753\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.7627 - accuracy: 0.6940\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.7448 - accuracy: 0.7141\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.7414\n",
      "Epoch 17/50\n",
      "20/44 [============>.................] - ETA: 0s - loss: 0.7005 - accuracy: 0.7312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25376\\2058373169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Fit GridSearchCV object to data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Print results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid shape for y: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m--> 135\u001b[1;33m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\noahv\\Programmeren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 53\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# Define function to create RNN model\n",
    "def create_model(lstm_size=50, num_layers=2, dropout=0.5, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    for i in range(num_layers):\n",
    "        model.add(LSTM(units=lstm_size, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(LSTM(units=lstm_size))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create KerasClassifier object\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Create dictionary for hyperparameters\n",
    "param_grid = {\n",
    "    'lstm_size': [25, 50, 100],\n",
    "    'num_layers': [2, 3, 4],\n",
    "    'dropout': [0.2, 0.3, 0.4, 0.5],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [50, 100, 150],\n",
    "    'optimizer': ['adam']\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Fit GridSearchCV object to data\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noahv\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 7s 7ms/step - loss: 2.2797 - accuracy: 0.4425\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2542 - accuracy: 0.4655\n",
      "22/22 [==============================] - 13s 6ms/step - loss: 2.2830 - accuracy: 0.3693\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 2.2588 - accuracy: 0.4770\n",
      "22/22 [==============================] - 6s 6ms/step - loss: 2.2804 - accuracy: 0.3434\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2561 - accuracy: 0.3132\n",
      "22/22 [==============================] - 6s 6ms/step - loss: 2.2636 - accuracy: 0.4368\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2286 - accuracy: 0.4454\n",
      "22/22 [==============================] - 5s 6ms/step - loss: 2.2676 - accuracy: 0.4713\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2351 - accuracy: 0.4799\n",
      "22/22 [==============================] - 5s 6ms/step - loss: 2.2695 - accuracy: 0.3951\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2369 - accuracy: 0.5546\n",
      "22/22 [==============================] - 8s 7ms/step - loss: 2.2774 - accuracy: 0.4440\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2469 - accuracy: 0.4454\n",
      "22/22 [==============================] - 7s 7ms/step - loss: 2.2821 - accuracy: 0.4454\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2564 - accuracy: 0.4799\n",
      "22/22 [==============================] - 9s 8ms/step - loss: 2.2784 - accuracy: 0.4440\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2459 - accuracy: 0.5546\n",
      "22/22 [==============================] - 7s 7ms/step - loss: 2.2656 - accuracy: 0.4928\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2356 - accuracy: 0.4454\n",
      "22/22 [==============================] - 8s 7ms/step - loss: 2.2675 - accuracy: 0.4756\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2336 - accuracy: 0.4799\n",
      "22/22 [==============================] - 7s 7ms/step - loss: 2.2658 - accuracy: 0.4339\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2313 - accuracy: 0.5546\n",
      "22/22 [==============================] - 6s 8ms/step - loss: 2.2753 - accuracy: 0.4152\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2412 - accuracy: 0.4454\n",
      "22/22 [==============================] - 5s 8ms/step - loss: 2.2763 - accuracy: 0.4325\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2421 - accuracy: 0.4799\n",
      "22/22 [==============================] - 5s 7ms/step - loss: 2.2751 - accuracy: 0.4210\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2385 - accuracy: 0.5776\n",
      "22/22 [==============================] - 5s 7ms/step - loss: 2.2606 - accuracy: 0.4842\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2220 - accuracy: 0.4454\n",
      "22/22 [==============================] - 5s 8ms/step - loss: 2.2578 - accuracy: 0.4655\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2145 - accuracy: 0.4799\n",
      "22/22 [==============================] - 6s 7ms/step - loss: 2.2596 - accuracy: 0.4382\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2150 - accuracy: 0.5546\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2722 - accuracy: 0.4799\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2339 - accuracy: 0.4454\n",
      "22/22 [==============================] - 8s 10ms/step - loss: 2.2753 - accuracy: 0.4770\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2392 - accuracy: 0.4799\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2756 - accuracy: 0.4526\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2387 - accuracy: 0.5546\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2545 - accuracy: 0.4971\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2109 - accuracy: 0.4454\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2634 - accuracy: 0.4828\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2246 - accuracy: 0.4799\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2523 - accuracy: 0.4497\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2000 - accuracy: 0.5546\n",
      "22/22 [==============================] - 6s 15ms/step - loss: 2.2668 - accuracy: 0.4756\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 2.2149 - accuracy: 0.4971\n",
      "22/22 [==============================] - 6s 15ms/step - loss: 2.2665 - accuracy: 0.4698\n",
      "11/11 [==============================] - 1s 8ms/step - loss: 2.2145 - accuracy: 0.5144\n",
      "22/22 [==============================] - 6s 17ms/step - loss: 2.2647 - accuracy: 0.4296\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 2.2014 - accuracy: 0.5603\n",
      "22/22 [==============================] - 6s 17ms/step - loss: 2.2427 - accuracy: 0.4928\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 2.1803 - accuracy: 0.4454\n",
      "22/22 [==============================] - 5s 15ms/step - loss: 2.2442 - accuracy: 0.4698\n",
      "11/11 [==============================] - 1s 8ms/step - loss: 2.1768 - accuracy: 0.4799\n",
      "22/22 [==============================] - 6s 16ms/step - loss: 2.2466 - accuracy: 0.4267\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 2.1794 - accuracy: 0.5546\n",
      "22/22 [==============================] - 7s 21ms/step - loss: 2.2619 - accuracy: 0.5000\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.2017 - accuracy: 0.4454\n",
      "22/22 [==============================] - 8s 21ms/step - loss: 2.2669 - accuracy: 0.5014\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.2113 - accuracy: 0.5144\n",
      "22/22 [==============================] - 7s 20ms/step - loss: 2.2609 - accuracy: 0.4440\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.1931 - accuracy: 0.5546\n",
      "22/22 [==============================] - 8s 21ms/step - loss: 2.2463 - accuracy: 0.4986\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.1870 - accuracy: 0.4454\n",
      "22/22 [==============================] - 7s 20ms/step - loss: 2.2453 - accuracy: 0.4784\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.1800 - accuracy: 0.4799\n",
      "22/22 [==============================] - 8s 21ms/step - loss: 2.2501 - accuracy: 0.4282\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.1861 - accuracy: 0.5546\n",
      "22/22 [==============================] - 5s 6ms/step - loss: 2.2806 - accuracy: 0.3434\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 2.2567 - accuracy: 0.4799\n",
      "22/22 [==============================] - 8s 7ms/step - loss: 2.2834 - accuracy: 0.3175\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 2.2589 - accuracy: 0.4799\n",
      "22/22 [==============================] - 9s 9ms/step - loss: 2.2836 - accuracy: 0.2902\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.2606 - accuracy: 0.5517\n",
      "22/22 [==============================] - 8s 7ms/step - loss: 2.2649 - accuracy: 0.4138\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.2337 - accuracy: 0.4454\n",
      "22/22 [==============================] - 7s 8ms/step - loss: 2.2689 - accuracy: 0.4195\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2398 - accuracy: 0.4799\n",
      "22/22 [==============================] - 7s 7ms/step - loss: 2.2718 - accuracy: 0.3793\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2423 - accuracy: 0.5546\n",
      "22/22 [==============================] - 10s 9ms/step - loss: 2.2807 - accuracy: 0.4670\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2548 - accuracy: 0.4454\n",
      "22/22 [==============================] - 9s 9ms/step - loss: 2.2785 - accuracy: 0.4483\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2494 - accuracy: 0.4799\n",
      "22/22 [==============================] - 10s 9ms/step - loss: 2.2819 - accuracy: 0.4310\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2549 - accuracy: 0.5546\n",
      "22/22 [==============================] - 9s 9ms/step - loss: 2.2660 - accuracy: 0.4756\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.2348 - accuracy: 0.4454\n",
      "22/22 [==============================] - 11s 10ms/step - loss: 2.2655 - accuracy: 0.4684\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2325 - accuracy: 0.4799\n",
      "22/22 [==============================] - 10s 9ms/step - loss: 2.2694 - accuracy: 0.4210\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2375 - accuracy: 0.5546\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2782 - accuracy: 0.3563\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2486 - accuracy: 0.4483\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2789 - accuracy: 0.3851\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2499 - accuracy: 0.4770\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2774 - accuracy: 0.3635\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2437 - accuracy: 0.5546\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2560 - accuracy: 0.4540\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2160 - accuracy: 0.4454\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2584 - accuracy: 0.4339\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2159 - accuracy: 0.4799\n",
      "22/22 [==============================] - 7s 9ms/step - loss: 2.2636 - accuracy: 0.4009\n",
      "11/11 [==============================] - 2s 4ms/step - loss: 2.2237 - accuracy: 0.5546\n",
      "22/22 [==============================] - 10s 11ms/step - loss: 2.2756 - accuracy: 0.4641\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.2421 - accuracy: 0.4454\n",
      "22/22 [==============================] - 9s 12ms/step - loss: 2.2755 - accuracy: 0.4626\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.2401 - accuracy: 0.4799\n",
      "22/22 [==============================] - 9s 12ms/step - loss: 2.2786 - accuracy: 0.4009\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.2461 - accuracy: 0.5546\n",
      "22/22 [==============================] - 9s 11ms/step - loss: 2.2574 - accuracy: 0.4971\n",
      "11/11 [==============================] - 3s 5ms/step - loss: 2.2181 - accuracy: 0.4454\n",
      "22/22 [==============================] - 9s 11ms/step - loss: 2.2574 - accuracy: 0.4770\n",
      "11/11 [==============================] - 2s 5ms/step - loss: 2.2122 - accuracy: 0.4799\n",
      "22/22 [==============================] - 9s 12ms/step - loss: 2.2584 - accuracy: 0.4310\n",
      "11/11 [==============================] - 3s 5ms/step - loss: 2.2143 - accuracy: 0.5546\n",
      "22/22 [==============================] - 7s 19ms/step - loss: 2.2705 - accuracy: 0.4468\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.2314 - accuracy: 0.4454\n",
      "22/22 [==============================] - 7s 18ms/step - loss: 2.2676 - accuracy: 0.4411\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.2223 - accuracy: 0.4799\n",
      "22/22 [==============================] - 7s 18ms/step - loss: 2.2710 - accuracy: 0.3764\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.2282 - accuracy: 0.5977\n",
      "22/22 [==============================] - 7s 20ms/step - loss: 2.2451 - accuracy: 0.4813\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.1895 - accuracy: 0.4454\n",
      "22/22 [==============================] - 7s 19ms/step - loss: 2.2472 - accuracy: 0.4713\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.1891 - accuracy: 0.4799\n",
      "22/22 [==============================] - 8s 19ms/step - loss: 2.2515 - accuracy: 0.4080\n",
      "11/11 [==============================] - 2s 6ms/step - loss: 2.1922 - accuracy: 0.5546\n",
      "22/22 [==============================] - 10s 26ms/step - loss: 2.2688 - accuracy: 0.4957\n",
      "11/11 [==============================] - 2s 7ms/step - loss: 2.2231 - accuracy: 0.4454\n",
      "22/22 [==============================] - 9s 24ms/step - loss: 2.2699 - accuracy: 0.4770\n",
      "11/11 [==============================] - 3s 7ms/step - loss: 2.2220 - accuracy: 0.4799\n",
      "22/22 [==============================] - 9s 26ms/step - loss: 2.2708 - accuracy: 0.4282\n",
      "11/11 [==============================] - 2s 7ms/step - loss: 2.2214 - accuracy: 0.5546\n",
      "22/22 [==============================] - 9s 24ms/step - loss: 2.2445 - accuracy: 0.4928\n",
      "11/11 [==============================] - 3s 7ms/step - loss: 2.1855 - accuracy: 0.4454\n",
      "22/22 [==============================] - 9s 26ms/step - loss: 2.2505 - accuracy: 0.4813\n",
      "11/11 [==============================] - 2s 7ms/step - loss: 2.1936 - accuracy: 0.4799\n",
      "22/22 [==============================] - 9s 23ms/step - loss: 2.2496 - accuracy: 0.4440\n",
      "11/11 [==============================] - 2s 7ms/step - loss: 2.1878 - accuracy: 0.5546\n",
      "33/33 [==============================] - 8s 20ms/step - loss: 2.2414 - accuracy: 0.4761\n",
      "Best: 0.523946 using {'dropout': 0.2, 'lstm_size': 100, 'num_layers': 2, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# Define function to create RNN model\n",
    "def create_model(lstm_size=50, num_layers=2, dropout=0.5, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    for i in range(num_layers):\n",
    "        model.add(LSTM(units=lstm_size, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(LSTM(units=lstm_size))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create KerasClassifier object\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "lstm_sizes = [25, 50, 100]\n",
    "num_layers = [2, 3, 4]\n",
    "dropouts = [0.2, 0.3, 0.4, 0.5]\n",
    "optimizers = ['adam']\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = dict(lstm_size=lstm_sizes, num_layers=num_layers, dropout=dropouts, optimizer=optimizers)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Fit GridSearchCV object to data\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17/17 [==============================] - 28s 187ms/step - loss: 2.2806 - accuracy: 0.4732 - val_loss: 2.2511 - val_accuracy: 0.5479\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 2.2331 - accuracy: 0.4933 - val_loss: 2.2020 - val_accuracy: 0.5479\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 2.1880 - accuracy: 0.4933 - val_loss: 2.1542 - val_accuracy: 0.5479\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 2.1441 - accuracy: 0.4933 - val_loss: 2.1085 - val_accuracy: 0.5479\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 2.1023 - accuracy: 0.4933 - val_loss: 2.0647 - val_accuracy: 0.5479\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 2.0620 - accuracy: 0.4933 - val_loss: 2.0228 - val_accuracy: 0.5479\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 2.0246 - accuracy: 0.4933 - val_loss: 1.9830 - val_accuracy: 0.5479\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.9875 - accuracy: 0.4933 - val_loss: 1.9448 - val_accuracy: 0.5479\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.9525 - accuracy: 0.4933 - val_loss: 1.9087 - val_accuracy: 0.5479\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.9208 - accuracy: 0.4933 - val_loss: 1.8745 - val_accuracy: 0.5479\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.8900 - accuracy: 0.4933 - val_loss: 1.8419 - val_accuracy: 0.5479\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.8597 - accuracy: 0.4933 - val_loss: 1.8111 - val_accuracy: 0.5479\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.8313 - accuracy: 0.4933 - val_loss: 1.7823 - val_accuracy: 0.5479\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.8058 - accuracy: 0.4933 - val_loss: 1.7547 - val_accuracy: 0.5479\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.7821 - accuracy: 0.4933 - val_loss: 1.7286 - val_accuracy: 0.5479\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.7590 - accuracy: 0.4933 - val_loss: 1.7044 - val_accuracy: 0.5479\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.7366 - accuracy: 0.4933 - val_loss: 1.6811 - val_accuracy: 0.5479\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.7151 - accuracy: 0.4933 - val_loss: 1.6592 - val_accuracy: 0.5479\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.6939 - accuracy: 0.4933 - val_loss: 1.6383 - val_accuracy: 0.5479\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.6780 - accuracy: 0.4933 - val_loss: 1.6187 - val_accuracy: 0.5479\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.6587 - accuracy: 0.4933 - val_loss: 1.6004 - val_accuracy: 0.5479\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.6439 - accuracy: 0.4933 - val_loss: 1.5830 - val_accuracy: 0.5479\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.6271 - accuracy: 0.4933 - val_loss: 1.5668 - val_accuracy: 0.5479\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.6147 - accuracy: 0.4933 - val_loss: 1.5512 - val_accuracy: 0.5479\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.6000 - accuracy: 0.4933 - val_loss: 1.5364 - val_accuracy: 0.5479\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 1.5879 - accuracy: 0.4933 - val_loss: 1.5224 - val_accuracy: 0.5479\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.5752 - accuracy: 0.4933 - val_loss: 1.5093 - val_accuracy: 0.5479\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.5610 - accuracy: 0.4933 - val_loss: 1.4969 - val_accuracy: 0.5479\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.5513 - accuracy: 0.4933 - val_loss: 1.4852 - val_accuracy: 0.5479\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 1.5405 - accuracy: 0.4933 - val_loss: 1.4740 - val_accuracy: 0.5479\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.5304 - accuracy: 0.4933 - val_loss: 1.4635 - val_accuracy: 0.5479\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.5209 - accuracy: 0.4933 - val_loss: 1.4536 - val_accuracy: 0.5479\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.5117 - accuracy: 0.4933 - val_loss: 1.4442 - val_accuracy: 0.5479\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.5019 - accuracy: 0.4933 - val_loss: 1.4351 - val_accuracy: 0.5479\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.4932 - accuracy: 0.4933 - val_loss: 1.4264 - val_accuracy: 0.5479\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.4853 - accuracy: 0.4933 - val_loss: 1.4182 - val_accuracy: 0.5479\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.4803 - accuracy: 0.4933 - val_loss: 1.4100 - val_accuracy: 0.5479\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.4719 - accuracy: 0.4933 - val_loss: 1.4024 - val_accuracy: 0.5479\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.4650 - accuracy: 0.4933 - val_loss: 1.3951 - val_accuracy: 0.5479\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.4573 - accuracy: 0.4933 - val_loss: 1.3882 - val_accuracy: 0.5479\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.4514 - accuracy: 0.4933 - val_loss: 1.3818 - val_accuracy: 0.5479\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.4455 - accuracy: 0.4933 - val_loss: 1.3752 - val_accuracy: 0.5479\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.4408 - accuracy: 0.4933 - val_loss: 1.3693 - val_accuracy: 0.5479\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.4352 - accuracy: 0.4933 - val_loss: 1.3636 - val_accuracy: 0.5479\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.4300 - accuracy: 0.4933 - val_loss: 1.3579 - val_accuracy: 0.5479\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 1.4241 - accuracy: 0.4933 - val_loss: 1.3527 - val_accuracy: 0.5479\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.4199 - accuracy: 0.4933 - val_loss: 1.3475 - val_accuracy: 0.5479\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.4147 - accuracy: 0.4933 - val_loss: 1.3427 - val_accuracy: 0.5479\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.4098 - accuracy: 0.4933 - val_loss: 1.3380 - val_accuracy: 0.5479\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.4065 - accuracy: 0.4933 - val_loss: 1.3335 - val_accuracy: 0.5479\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 1.4007 - accuracy: 0.4933 - val_loss: 1.3291 - val_accuracy: 0.5479\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.3984 - accuracy: 0.4933 - val_loss: 1.3248 - val_accuracy: 0.5479\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 1.3944 - accuracy: 0.4933 - val_loss: 1.3208 - val_accuracy: 0.5479\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.3899 - accuracy: 0.4933 - val_loss: 1.3168 - val_accuracy: 0.5479\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.3862 - accuracy: 0.4933 - val_loss: 1.3130 - val_accuracy: 0.5479\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.3829 - accuracy: 0.4933 - val_loss: 1.3094 - val_accuracy: 0.5479\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3790 - accuracy: 0.4933 - val_loss: 1.3059 - val_accuracy: 0.5479\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3755 - accuracy: 0.4933 - val_loss: 1.3024 - val_accuracy: 0.5479\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3708 - accuracy: 0.4933 - val_loss: 1.2992 - val_accuracy: 0.5479\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3686 - accuracy: 0.4933 - val_loss: 1.2959 - val_accuracy: 0.5479\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.3651 - accuracy: 0.4933 - val_loss: 1.2929 - val_accuracy: 0.5479\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3625 - accuracy: 0.4933 - val_loss: 1.2900 - val_accuracy: 0.5479\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3589 - accuracy: 0.4933 - val_loss: 1.2870 - val_accuracy: 0.5479\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.3570 - accuracy: 0.4933 - val_loss: 1.2842 - val_accuracy: 0.5479\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3532 - accuracy: 0.4933 - val_loss: 1.2814 - val_accuracy: 0.5479\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3521 - accuracy: 0.4933 - val_loss: 1.2788 - val_accuracy: 0.5479\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3485 - accuracy: 0.4933 - val_loss: 1.2762 - val_accuracy: 0.5479\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.3460 - accuracy: 0.4933 - val_loss: 1.2737 - val_accuracy: 0.5479\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3434 - accuracy: 0.4933 - val_loss: 1.2713 - val_accuracy: 0.5479\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3430 - accuracy: 0.4933 - val_loss: 1.2688 - val_accuracy: 0.5479\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.3412 - accuracy: 0.4933 - val_loss: 1.2666 - val_accuracy: 0.5479\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.3372 - accuracy: 0.4933 - val_loss: 1.2644 - val_accuracy: 0.5479\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3348 - accuracy: 0.4933 - val_loss: 1.2621 - val_accuracy: 0.5479\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3338 - accuracy: 0.4933 - val_loss: 1.2599 - val_accuracy: 0.5479\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.3309 - accuracy: 0.4933 - val_loss: 1.2579 - val_accuracy: 0.5479\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.3263 - accuracy: 0.4933 - val_loss: 1.2560 - val_accuracy: 0.5479\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.3246 - accuracy: 0.4933 - val_loss: 1.2541 - val_accuracy: 0.5479\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3237 - accuracy: 0.4933 - val_loss: 1.2524 - val_accuracy: 0.5479\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.3255 - accuracy: 0.4933 - val_loss: 1.2505 - val_accuracy: 0.5479\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3202 - accuracy: 0.4933 - val_loss: 1.2485 - val_accuracy: 0.5479\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3191 - accuracy: 0.4933 - val_loss: 1.2468 - val_accuracy: 0.5479\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3190 - accuracy: 0.4933 - val_loss: 1.2452 - val_accuracy: 0.5479\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.3170 - accuracy: 0.4933 - val_loss: 1.2433 - val_accuracy: 0.5479\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.3127 - accuracy: 0.4933 - val_loss: 1.2417 - val_accuracy: 0.5479\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.3115 - accuracy: 0.4933 - val_loss: 1.2400 - val_accuracy: 0.5479\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.3107 - accuracy: 0.4933 - val_loss: 1.2386 - val_accuracy: 0.5479\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.3081 - accuracy: 0.4933 - val_loss: 1.2370 - val_accuracy: 0.5479\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.3092 - accuracy: 0.4933 - val_loss: 1.2353 - val_accuracy: 0.5479\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.3078 - accuracy: 0.4933 - val_loss: 1.2339 - val_accuracy: 0.5479\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.3052 - accuracy: 0.4933 - val_loss: 1.2324 - val_accuracy: 0.5479\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3021 - accuracy: 0.4933 - val_loss: 1.2311 - val_accuracy: 0.5479\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3022 - accuracy: 0.4933 - val_loss: 1.2299 - val_accuracy: 0.5479\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.3023 - accuracy: 0.4933 - val_loss: 1.2285 - val_accuracy: 0.5479\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3000 - accuracy: 0.4933 - val_loss: 1.2272 - val_accuracy: 0.5479\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.3006 - accuracy: 0.4933 - val_loss: 1.2259 - val_accuracy: 0.5479\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2974 - accuracy: 0.4933 - val_loss: 1.2246 - val_accuracy: 0.5479\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2951 - accuracy: 0.4933 - val_loss: 1.2235 - val_accuracy: 0.5479\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2959 - accuracy: 0.4933 - val_loss: 1.2223 - val_accuracy: 0.5479\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2941 - accuracy: 0.4933 - val_loss: 1.2212 - val_accuracy: 0.5479\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2904 - accuracy: 0.4933 - val_loss: 1.2201 - val_accuracy: 0.5479\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2921 - accuracy: 0.4933 - val_loss: 1.2189 - val_accuracy: 0.5479\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2903 - accuracy: 0.4933 - val_loss: 1.2179 - val_accuracy: 0.5479\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.2889 - accuracy: 0.4933 - val_loss: 1.2168 - val_accuracy: 0.5479\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.2890 - accuracy: 0.4933 - val_loss: 1.2158 - val_accuracy: 0.5479\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2890 - accuracy: 0.4933 - val_loss: 1.2148 - val_accuracy: 0.5479\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2852 - accuracy: 0.4933 - val_loss: 1.2138 - val_accuracy: 0.5479\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2857 - accuracy: 0.4933 - val_loss: 1.2127 - val_accuracy: 0.5479\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 1.2861 - accuracy: 0.4933 - val_loss: 1.2118 - val_accuracy: 0.5479\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2836 - accuracy: 0.4933 - val_loss: 1.2109 - val_accuracy: 0.5479\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2830 - accuracy: 0.4933 - val_loss: 1.2101 - val_accuracy: 0.5479\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.2845 - accuracy: 0.4933 - val_loss: 1.2092 - val_accuracy: 0.5479\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2821 - accuracy: 0.4933 - val_loss: 1.2085 - val_accuracy: 0.5479\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2799 - accuracy: 0.4933 - val_loss: 1.2076 - val_accuracy: 0.5479\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2799 - accuracy: 0.4933 - val_loss: 1.2067 - val_accuracy: 0.5479\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2788 - accuracy: 0.4933 - val_loss: 1.2059 - val_accuracy: 0.5479\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2803 - accuracy: 0.4933 - val_loss: 1.2052 - val_accuracy: 0.5479\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2776 - accuracy: 0.4933 - val_loss: 1.2043 - val_accuracy: 0.5479\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2781 - accuracy: 0.4933 - val_loss: 1.2036 - val_accuracy: 0.5479\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2758 - accuracy: 0.4933 - val_loss: 1.2028 - val_accuracy: 0.5479\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2771 - accuracy: 0.4933 - val_loss: 1.2021 - val_accuracy: 0.5479\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2736 - accuracy: 0.4933 - val_loss: 1.2014 - val_accuracy: 0.5479\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2725 - accuracy: 0.4933 - val_loss: 1.2008 - val_accuracy: 0.5479\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2743 - accuracy: 0.4933 - val_loss: 1.2000 - val_accuracy: 0.5479\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2710 - accuracy: 0.4933 - val_loss: 1.1993 - val_accuracy: 0.5479\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2737 - accuracy: 0.4933 - val_loss: 1.1987 - val_accuracy: 0.5479\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2731 - accuracy: 0.4933 - val_loss: 1.1980 - val_accuracy: 0.5479\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2723 - accuracy: 0.4933 - val_loss: 1.1973 - val_accuracy: 0.5479\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2696 - accuracy: 0.4933 - val_loss: 1.1967 - val_accuracy: 0.5479\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2698 - accuracy: 0.4933 - val_loss: 1.1960 - val_accuracy: 0.5479\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2683 - accuracy: 0.4933 - val_loss: 1.1954 - val_accuracy: 0.5479\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2664 - accuracy: 0.4933 - val_loss: 1.1948 - val_accuracy: 0.5479\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2665 - accuracy: 0.4933 - val_loss: 1.1942 - val_accuracy: 0.5479\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2671 - accuracy: 0.4933 - val_loss: 1.1935 - val_accuracy: 0.5479\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2633 - accuracy: 0.4933 - val_loss: 1.1930 - val_accuracy: 0.5479\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2661 - accuracy: 0.4933 - val_loss: 1.1924 - val_accuracy: 0.5479\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2635 - accuracy: 0.4933 - val_loss: 1.1918 - val_accuracy: 0.5479\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2666 - accuracy: 0.4933 - val_loss: 1.1912 - val_accuracy: 0.5479\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 1.2657 - accuracy: 0.4933 - val_loss: 1.1907 - val_accuracy: 0.5479\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2603 - accuracy: 0.4933 - val_loss: 1.1900 - val_accuracy: 0.5479\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2631 - accuracy: 0.4933 - val_loss: 1.1896 - val_accuracy: 0.5479\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2637 - accuracy: 0.4933 - val_loss: 1.1892 - val_accuracy: 0.5479\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2617 - accuracy: 0.4933 - val_loss: 1.1886 - val_accuracy: 0.5479\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2619 - accuracy: 0.4933 - val_loss: 1.1881 - val_accuracy: 0.5479\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.2643 - accuracy: 0.4933 - val_loss: 1.1878 - val_accuracy: 0.5479\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2596 - accuracy: 0.4933 - val_loss: 1.1873 - val_accuracy: 0.5479\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2612 - accuracy: 0.4933 - val_loss: 1.1868 - val_accuracy: 0.5479\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2607 - accuracy: 0.4933 - val_loss: 1.1861 - val_accuracy: 0.5479\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.2562 - accuracy: 0.4933 - val_loss: 1.1857 - val_accuracy: 0.5479\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.2608 - accuracy: 0.4933 - val_loss: 1.1853 - val_accuracy: 0.5479\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.2575 - accuracy: 0.4933 - val_loss: 1.1847 - val_accuracy: 0.5479\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2591 - accuracy: 0.4933 - val_loss: 1.1842 - val_accuracy: 0.5479\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2574 - accuracy: 0.4933 - val_loss: 1.1837 - val_accuracy: 0.5479\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2568 - accuracy: 0.4933 - val_loss: 1.1832 - val_accuracy: 0.5479\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2563 - accuracy: 0.4933 - val_loss: 1.1829 - val_accuracy: 0.5479\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2556 - accuracy: 0.4933 - val_loss: 1.1824 - val_accuracy: 0.5479\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.2556 - accuracy: 0.4933 - val_loss: 1.1821 - val_accuracy: 0.5479\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.2557 - accuracy: 0.4933 - val_loss: 1.1817 - val_accuracy: 0.5479\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2544 - accuracy: 0.4933 - val_loss: 1.1812 - val_accuracy: 0.5479\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2558 - accuracy: 0.4933 - val_loss: 1.1807 - val_accuracy: 0.5479\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2534 - accuracy: 0.4933 - val_loss: 1.1804 - val_accuracy: 0.5479\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2569 - accuracy: 0.4933 - val_loss: 1.1800 - val_accuracy: 0.5479\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2539 - accuracy: 0.4933 - val_loss: 1.1799 - val_accuracy: 0.5479\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2555 - accuracy: 0.4933 - val_loss: 1.1796 - val_accuracy: 0.5479\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2551 - accuracy: 0.4933 - val_loss: 1.1793 - val_accuracy: 0.5479\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2508 - accuracy: 0.4933 - val_loss: 1.1788 - val_accuracy: 0.5479\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2494 - accuracy: 0.4933 - val_loss: 1.1786 - val_accuracy: 0.5479\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 1.2530 - accuracy: 0.4933 - val_loss: 1.1783 - val_accuracy: 0.5479\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2507 - accuracy: 0.4933 - val_loss: 1.1780 - val_accuracy: 0.5479\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2528 - accuracy: 0.4933 - val_loss: 1.1776 - val_accuracy: 0.5479\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2522 - accuracy: 0.4933 - val_loss: 1.1774 - val_accuracy: 0.5479\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2510 - accuracy: 0.4933 - val_loss: 1.1770 - val_accuracy: 0.5479\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2539 - accuracy: 0.4933 - val_loss: 1.1768 - val_accuracy: 0.5479\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.2519 - accuracy: 0.4933 - val_loss: 1.1765 - val_accuracy: 0.5479\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.2521 - accuracy: 0.4933 - val_loss: 1.1763 - val_accuracy: 0.5479\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2494 - accuracy: 0.4933 - val_loss: 1.1760 - val_accuracy: 0.5479\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2499 - accuracy: 0.4933 - val_loss: 1.1756 - val_accuracy: 0.5479\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2479 - accuracy: 0.4933 - val_loss: 1.1752 - val_accuracy: 0.5479\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2492 - accuracy: 0.4933 - val_loss: 1.1750 - val_accuracy: 0.5479\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2483 - accuracy: 0.4933 - val_loss: 1.1747 - val_accuracy: 0.5479\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2522 - accuracy: 0.4933 - val_loss: 1.1743 - val_accuracy: 0.5479\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2463 - accuracy: 0.4933 - val_loss: 1.1741 - val_accuracy: 0.5479\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2480 - accuracy: 0.4933 - val_loss: 1.1738 - val_accuracy: 0.5479\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2459 - accuracy: 0.4933 - val_loss: 1.1736 - val_accuracy: 0.5479\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2452 - accuracy: 0.4933 - val_loss: 1.1733 - val_accuracy: 0.5479\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2468 - accuracy: 0.4933 - val_loss: 1.1732 - val_accuracy: 0.5479\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 1.2424 - accuracy: 0.4933 - val_loss: 1.1729 - val_accuracy: 0.5479\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2450 - accuracy: 0.4933 - val_loss: 1.1726 - val_accuracy: 0.5479\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2452 - accuracy: 0.4933 - val_loss: 1.1724 - val_accuracy: 0.5479\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2473 - accuracy: 0.4933 - val_loss: 1.1722 - val_accuracy: 0.5479\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2472 - accuracy: 0.4933 - val_loss: 1.1720 - val_accuracy: 0.5479\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 1.2492 - accuracy: 0.4933 - val_loss: 1.1718 - val_accuracy: 0.5479\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 1.2463 - accuracy: 0.4933 - val_loss: 1.1717 - val_accuracy: 0.5479\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2458 - accuracy: 0.4933 - val_loss: 1.1714 - val_accuracy: 0.5479\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2466 - accuracy: 0.4933 - val_loss: 1.1712 - val_accuracy: 0.5479\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2434 - accuracy: 0.4933 - val_loss: 1.1708 - val_accuracy: 0.5479\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2471 - accuracy: 0.4933 - val_loss: 1.1706 - val_accuracy: 0.5479\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2439 - accuracy: 0.4933 - val_loss: 1.1703 - val_accuracy: 0.5479\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 1.2423 - accuracy: 0.4933 - val_loss: 1.1701 - val_accuracy: 0.5479\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 1.2428 - accuracy: 0.4933 - val_loss: 1.1699 - val_accuracy: 0.5479\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 1.2446 - accuracy: 0.4933 - val_loss: 1.1696 - val_accuracy: 0.5479\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.1696 - accuracy: 0.5479\n",
      "Test loss: 1.1696449518203735\n",
      "Test accuracy: 0.5478927493095398\n"
     ]
    }
   ],
   "source": [
    "# Define the input and target variables\n",
    "X = df.drop([\"date\", \"mood\"], axis=1) # drop the date and target columns\n",
    "y = df[\"mood\"]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features using StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Encode target variable using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Reshape input data to fit RNN input shape\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Define RNN model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
