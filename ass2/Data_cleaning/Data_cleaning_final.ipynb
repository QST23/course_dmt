{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_nan_column runtime: 0.07 seconds\n",
      "add_zero_column runtime: 0.08 seconds\n",
      "impute_prop_location_score2_using_mean_score1 runtime: 13.34 seconds\n",
      "impute_prop_review_score runtime: 0.26 seconds\n",
      "impute_orig_destination_distance runtime: 0.68 seconds\n",
      "define_target runtime: 0.08 seconds\n",
      "visitor_hist_starrating\n",
      "visitor_hist_adr_usd\n",
      "srch_query_affinity_score\n",
      "comp1_rate\n",
      "comp1_inv\n",
      "comp1_rate_percent_diff\n",
      "comp2_rate\n",
      "comp2_inv\n",
      "comp2_rate_percent_diff\n",
      "comp3_rate\n",
      "comp3_inv\n",
      "comp3_rate_percent_diff\n",
      "comp4_rate\n",
      "comp4_inv\n",
      "comp4_rate_percent_diff\n",
      "comp5_rate\n",
      "comp5_inv\n",
      "comp5_rate_percent_diff\n",
      "comp6_rate\n",
      "comp6_inv\n",
      "comp6_rate_percent_diff\n",
      "comp7_rate\n",
      "comp7_inv\n",
      "comp7_rate_percent_diff\n",
      "comp8_rate\n",
      "comp8_inv\n",
      "comp8_rate_percent_diff\n",
      "gross_bookings_usd\n",
      "drop_nan_columns runtime: 29.91 seconds\n",
      "         srch_id  site_id  visitor_location_country_id  prop_country_id  \\\n",
      "0              1       12                          187              219   \n",
      "1              1       12                          187              219   \n",
      "2              1       12                          187              219   \n",
      "3              1       12                          187              219   \n",
      "4              1       12                          187              219   \n",
      "...          ...      ...                          ...              ...   \n",
      "4958342   332785        5                          219              219   \n",
      "4958343   332785        5                          219              219   \n",
      "4958344   332785        5                          219              219   \n",
      "4958345   332785        5                          219              219   \n",
      "4958346   332785        5                          219              219   \n",
      "\n",
      "         prop_id  prop_starrating  prop_review_score  prop_brand_bool  \\\n",
      "0            893                3                3.5                1   \n",
      "1          10404                4                4.0                1   \n",
      "2          21315                3                4.5                1   \n",
      "3          27348                2                4.0                1   \n",
      "4          29604                4                3.5                1   \n",
      "...          ...              ...                ...              ...   \n",
      "4958342    77700                3                4.0                1   \n",
      "4958343    88083                3                4.0                1   \n",
      "4958344    94508                3                3.5                1   \n",
      "4958345   128360                3                5.0                1   \n",
      "4958346   134949                3                2.5                1   \n",
      "\n",
      "         prop_location_score1  prop_location_score2  ...  \\\n",
      "0                        2.83              0.043800  ...   \n",
      "1                        2.20              0.014900  ...   \n",
      "2                        2.20              0.024500  ...   \n",
      "3                        2.83              0.012500  ...   \n",
      "4                        2.64              0.124100  ...   \n",
      "...                       ...                   ...  ...   \n",
      "4958342                  1.61              0.047100  ...   \n",
      "4958343                  1.95              0.152000  ...   \n",
      "4958344                  1.10              0.016400  ...   \n",
      "4958345                  1.95              0.066200  ...   \n",
      "4958346                  1.10              0.048962  ...   \n",
      "\n",
      "         srch_saturday_night_bool  orig_destination_distance  random_bool  \\\n",
      "0                               1                1776.833608            1   \n",
      "1                               1                1760.058186            1   \n",
      "2                               1                1760.820221            1   \n",
      "3                               1                1786.456451            1   \n",
      "4                               1                1857.881111            1   \n",
      "...                           ...                        ...          ...   \n",
      "4958342                         0                 550.920000            0   \n",
      "4958343                         0                 553.140000            0   \n",
      "4958344                         0                 544.430000            0   \n",
      "4958345                         0                 550.380000            0   \n",
      "4958346                         0                 583.250000            0   \n",
      "\n",
      "         click_bool  booking_bool  prop_review_score_is_nan  \\\n",
      "0                 0             0                         0   \n",
      "1                 0             0                         0   \n",
      "2                 0             0                         0   \n",
      "3                 0             0                         0   \n",
      "4                 0             0                         0   \n",
      "...             ...           ...                       ...   \n",
      "4958342           0             0                         0   \n",
      "4958343           0             0                         0   \n",
      "4958344           0             0                         0   \n",
      "4958345           1             1                         0   \n",
      "4958346           0             0                         0   \n",
      "\n",
      "         srch_query_affinity_score_is_nan  prop_review_score_is_zero  \\\n",
      "0                                       1                          0   \n",
      "1                                       1                          0   \n",
      "2                                       1                          0   \n",
      "3                                       1                          0   \n",
      "4                                       1                          0   \n",
      "...                                   ...                        ...   \n",
      "4958342                                 1                          0   \n",
      "4958343                                 1                          0   \n",
      "4958344                                 1                          0   \n",
      "4958345                                 1                          0   \n",
      "4958346                                 1                          0   \n",
      "\n",
      "         prop_starrating_is_zero  target  \n",
      "0                              0       0  \n",
      "1                              0       0  \n",
      "2                              0       0  \n",
      "3                              0       0  \n",
      "4                              0       0  \n",
      "...                          ...     ...  \n",
      "4958342                        0       0  \n",
      "4958343                        0       0  \n",
      "4958344                        0       0  \n",
      "4958345                        0       6  \n",
      "4958346                        0       0  \n",
      "\n",
      "[4958347 rows x 30 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9260\\1956761586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/noahv/Data-Mining-techniques/course_dmt/ass2/datasets/training_set_VU_DM.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9260\\1956761586.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprint_columns_containing_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrescaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data_cleaned.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9260\\1956761586.py\u001b[0m in \u001b[0;36mrescaler\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;31m#rescale all columns to [0,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrescaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;31m# except for the id columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def add_nan_column(df, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_nan'] = df[col].isna().astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_nan_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_zero_column(df, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_zero'] = df[col].eq(0).astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_zero_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def calc_price_per_night(df: pd.DataFrame):\n",
    "\n",
    "\n",
    "# Function to impute the prop_location_score2 values that are NaN based on the prop_location_score2 values of the same prop_id\n",
    "def impute_prop_loc_score2_using_future_score2(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Retrieve the prop_ids that have a change in prop_location_score2 from NaN to a float over time\n",
    "    has_change_over_time = df.groupby('prop_id')['prop_location_score2'].apply(lambda x: x.diff().notna().any())\n",
    "    prop_ids_change = has_change_over_time[has_change_over_time == True].index\n",
    "\n",
    "    # For each prop_id that has a change in prop_location_score2 from NaN to a float over time, impute the NaN values with the first non-NaN value\n",
    "    for prop_id in prop_ids_change:\n",
    "        mask = (df['prop_id'] == prop_id) & (df['prop_location_score2'].isnull())\n",
    "        non_nan_value = df.loc[(df['prop_id'] == prop_id) & (df['prop_location_score2'].notna()), 'prop_location_score2'].values[0]\n",
    "        df.loc[mask, 'prop_location_score2'] = non_nan_value\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_loc_score2_using_future_score2 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Impute remaning NaN values using the mean prop_locatioin_score2 values for each prop_location_score1 value\n",
    "def impute_prop_location_score2_using_mean_score1(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create an extra column with rounded 'prop_location_score1'\n",
    "    df['rounded_score1'] = df['prop_location_score1'].round()\n",
    "\n",
    "    # Calculate the mean of 'prop_location_score2' for each rounded integer value\n",
    "    mean_score2_by_rounded = df.groupby('rounded_score1')['prop_location_score2'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_location_score2' based on rounded integer values\n",
    "    df['prop_location_score2'].fillna(df['rounded_score1'].map(mean_score2_by_rounded), inplace=True)\n",
    "\n",
    "    # Drop the extra column 'rounded_score1' if no longer needed\n",
    "    df.drop('rounded_score1', axis=1, inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_location_score2_using_mean_score1 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_prop_review_score(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean of 'prop_review_score' for each rounded integer value\n",
    "    mean_review_score_for_starrating = df.groupby('prop_starrating')['prop_review_score'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_review_score' based on rounded integer values\n",
    "    df['prop_review_score'].fillna(df['prop_starrating'].map(mean_review_score_for_starrating), inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_review_score runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def impute_prop_starrating(df: pd.DataFrame):\n",
    "\n",
    "#def impute_query_affinity_score(df: pd.DataFrame):\n",
    "\n",
    "\n",
    "# Calculate the mean distance per hotel and impute the NaN values with the mean distance\n",
    "def impute_orig_destination_distance(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean distance per hotel\n",
    "    mean_distance_per_hotel = df.groupby('prop_id')['orig_destination_distance'].mean()\n",
    "    \n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['prop_id'].map(mean_distance_per_hotel), inplace=True)\n",
    "\n",
    "    # BUT there are also hotels that contain only NaN values for orig_destination_distance, \n",
    "    # for these we impute it with the mean distance for the country_id\n",
    "    # Use visitor_location_country_id or country_id?\n",
    "\n",
    "    # Calculate the mean distance per country\n",
    "    mean_distance_per_country = df.groupby('visitor_location_country_id')['orig_destination_distance'].mean()\n",
    "\n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['visitor_location_country_id'].map(mean_distance_per_country), inplace=True)\n",
    "    \n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_orig_destination_distance runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def define_target(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    df['target'] = df['click_bool'] +  df['booking_bool'] * 5\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"define_target runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode(df, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"one_hot_encode runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_id_columns(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.endswith('_id'):\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"delete_id_columns runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_nan_columns(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            print(col)\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"drop_nan_columns runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_columns_containing_string(df):\n",
    "    matching_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    if matching_columns:\n",
    "        print(\"Columns containing string values:\")\n",
    "        for col in matching_columns:\n",
    "            print(col)\n",
    "\n",
    "\n",
    "def remove_column(df, column_name):\n",
    "    df = df.drop(column_name, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "#rescale all columns to [0,1]\n",
    "def rescaler(df):\n",
    "    for col in df.columns:\n",
    "        # except for the id columns\n",
    "        if not col.endswith('_id'):\n",
    "            df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    df = remove_column(df, 'date_time')\n",
    "    df = add_nan_column(df, ['prop_review_score', 'srch_query_affinity_score'])\n",
    "    df = add_zero_column(df, ['prop_review_score', 'prop_starrating'])\n",
    "    #df = impute_prop_loc_score2_using_future_score2(df)\n",
    "    df = impute_prop_location_score2_using_mean_score1(df)\n",
    "    df = impute_prop_review_score(df)\n",
    "    df = impute_orig_destination_distance(df)\n",
    "    df = define_target(df)\n",
    "    #df = one_hot_encode(df, ['prop_country_id', 'visitor_location_country_id','prop_id'])\n",
    "    #df = delete_id_columns(df)\n",
    "    df = drop_nan_columns(df)\n",
    "    print(df)\n",
    "    df = print_columns_containing_string(df)\n",
    "    df = rescaler(df)\n",
    "    df.to_csv('data_cleaned.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('/Users/noahv/Data-Mining-techniques/course_dmt/ass2/datasets/training_set_VU_DM.csv')\n",
    "main(df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAN THE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def add_nan_column(df, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_nan'] = df[col].isna().astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_nan_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_zero_column(df, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_zero'] = df[col].eq(0).astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_zero_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def calc_price_per_night(df: pd.DataFrame):\n",
    "\n",
    "\n",
    "# Function to impute the prop_location_score2 values that are NaN based on the prop_location_score2 values of the same prop_id\n",
    "def impute_prop_loc_score2_using_future_score2(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Retrieve the prop_ids that have a change in prop_location_score2 from NaN to a float over time\n",
    "    has_change_over_time = df.groupby('prop_id')['prop_location_score2'].apply(lambda x: x.diff().notna().any())\n",
    "    prop_ids_change = has_change_over_time[has_change_over_time == True].index\n",
    "\n",
    "    # For each prop_id that has a change in prop_location_score2 from NaN to a float over time, impute the NaN values with the first non-NaN value\n",
    "    for prop_id in prop_ids_change:\n",
    "        mask = (df['prop_id'] == prop_id) & (df['prop_location_score2'].isnull())\n",
    "        non_nan_value = df.loc[(df['prop_id'] == prop_id) & (df['prop_location_score2'].notna()), 'prop_location_score2'].values[0]\n",
    "        df.loc[mask, 'prop_location_score2'] = non_nan_value\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_loc_score2_using_future_score2 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Impute remaning NaN values using the mean prop_locatioin_score2 values for each prop_location_score1 value\n",
    "def impute_prop_location_score2_using_mean_score1(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create an extra column with rounded 'prop_location_score1'\n",
    "    df['rounded_score1'] = df['prop_location_score1'].round()\n",
    "\n",
    "    # Calculate the mean of 'prop_location_score2' for each rounded integer value\n",
    "    mean_score2_by_rounded = df.groupby('rounded_score1')['prop_location_score2'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_location_score2' based on rounded integer values\n",
    "    df['prop_location_score2'].fillna(df['rounded_score1'].map(mean_score2_by_rounded), inplace=True)\n",
    "\n",
    "    # Drop the extra column 'rounded_score1' if no longer needed\n",
    "    df.drop('rounded_score1', axis=1, inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_location_score2_using_mean_score1 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_prop_review_score(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean of 'prop_review_score' for each rounded integer value\n",
    "    mean_review_score_for_starrating = df.groupby('prop_starrating')['prop_review_score'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_review_score' based on rounded integer values\n",
    "    df['prop_review_score'].fillna(df['prop_starrating'].map(mean_review_score_for_starrating), inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_review_score runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def impute_prop_starrating(df: pd.DataFrame):\n",
    "\n",
    "#def impute_query_affinity_score(df: pd.DataFrame):\n",
    "\n",
    "\n",
    "# Calculate the mean distance per hotel and impute the NaN values with the mean distance\n",
    "def impute_orig_destination_distance(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean distance per hotel\n",
    "    mean_distance_per_hotel = df.groupby('prop_id')['orig_destination_distance'].mean()\n",
    "    \n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['prop_id'].map(mean_distance_per_hotel), inplace=True)\n",
    "\n",
    "    # BUT there are also hotels that contain only NaN values for orig_destination_distance, \n",
    "    # for these we impute it with the mean distance for the country_id\n",
    "    # Use visitor_location_country_id or country_id?\n",
    "\n",
    "    # Calculate the mean distance per country\n",
    "    mean_distance_per_country = df.groupby('visitor_location_country_id')['orig_destination_distance'].mean()\n",
    "\n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['visitor_location_country_id'].map(mean_distance_per_country), inplace=True)\n",
    "    \n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_orig_destination_distance runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def define_target(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    df['target'] = df['click_bool'] +  df['booking_bool'] * 5\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"define_target runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode(df, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"one_hot_encode runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_id_columns(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.endswith('_id'):\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"delete_id_columns runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#rescale all columns to [0,1]\n",
    "def rescaler(df):\n",
    "    for col in df.columns:\n",
    "        # except for the id columns\n",
    "        if col.endswith('_id') is False:\n",
    "            df = df.with_columns(\n",
    "                (pl.col(col) - pl.col(col).min()) / (pl.col(col).max() - pl.col(col).min())\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    df = add_nan_column(df, ['prop_review_score', 'srch_query_affinity_score'])\n",
    "    df = add_zero_column(df, ['prop_review_score', 'prop_starrating'])\n",
    "    #df = impute_prop_loc_score2_using_future_score2(df)\n",
    "    df = impute_prop_location_score2_using_mean_score1(df)\n",
    "    df = impute_prop_review_score(df)\n",
    "    df = impute_orig_destination_distance(df)\n",
    "    df = define_target(df)\n",
    "    df = one_hot_encode(df, ['prop_country_id', 'visitor_location_country_id','prop_id'])\n",
    "    df = delete_id_columns(df)\n",
    "    df = rescaler(df)\n",
    "    df.to_csv('test_data_cleaned.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('/Users/noahv/Data-Mining-techniques/course_dmt/ass2/datasets/test_set_VU_DM.csv')\n",
    "main(df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
