{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# df = pd.read_csv('/Users/noahv/Data-Mining-techniques/course_dmt/ass2/datasets/training_set_VU_DM.csv')\n",
    "# df\n",
    "# n = int(len(df) * 0.1)\n",
    "\n",
    "# first_10_percent = df.head(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_nan_column runtime: 0.23 seconds\n",
      "add_zero_column runtime: 0.21 seconds\n",
      "impute_prop_location_score2_using_mean_score1 runtime: 15.58 seconds\n",
      "impute_prop_review_score runtime: 0.61 seconds\n",
      "impute_orig_destination_distance runtime: 1.30 seconds\n",
      "drop_nan_columns runtime: 38.24 seconds\n"
     ]
    }
   ],
   "source": [
    "def remove_column(df : pd.DataFrame, column_name):\n",
    "    df = df.drop(column_name, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_nan_column(df : pd.DataFrame, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_nan'] = df[col].isna().astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_nan_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_zero_column(df : pd.DataFrame, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_zero'] = df[col].eq(0).astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_zero_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Calculates the price per night where we know the length of stay is equal to 1 for each prop_id\n",
    "def price_per_night_single_stays(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mask = df['srch_length_of_stay'] == 1\n",
    "    df['mean_price_per_night'] = df.groupby('prop_id')['price_usd'].transform(lambda x: x[mask].mean())\n",
    "    return df\n",
    "\n",
    "\n",
    "# def price_per_night_multiple_stays\n",
    "\n",
    "\n",
    "# Function to impute the prop_location_score2 values that are NaN based on the prop_location_score2 values of the same prop_id\n",
    "def impute_prop_loc_score2_using_future_score2(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Retrieve the prop_ids that have a change in prop_location_score2 from NaN to a float over time\n",
    "    has_change_over_time = df.groupby('prop_id')['prop_location_score2'].apply(lambda x: x.diff().notna().any())\n",
    "    prop_ids_change = has_change_over_time[has_change_over_time == True].index\n",
    "\n",
    "    # For each prop_id that has a change in prop_location_score2 from NaN to a float over time, impute the NaN values with the first non-NaN value\n",
    "    for prop_id in prop_ids_change:\n",
    "        mask = (df['prop_id'] == prop_id) & (df['prop_location_score2'].isnull())\n",
    "        non_nan_value = df.loc[(df['prop_id'] == prop_id) & (df['prop_location_score2'].notna()), 'prop_location_score2'].values[0]\n",
    "        df.loc[mask, 'prop_location_score2'] = non_nan_value\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_loc_score2_using_future_score2 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Impute remaning NaN values using the mean prop_locatioin_score2 values for each prop_location_score1 value\n",
    "def impute_prop_location_score2_using_mean_score1(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create an extra column with rounded 'prop_location_score1'\n",
    "    df['rounded_score1'] = df['prop_location_score1'].round()\n",
    "\n",
    "    # Calculate the mean of 'prop_location_score2' for each rounded integer value\n",
    "    mean_score2_by_rounded = df.groupby('rounded_score1')['prop_location_score2'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_location_score2' based on rounded integer values\n",
    "    df['prop_location_score2'].fillna(df['rounded_score1'].map(mean_score2_by_rounded), inplace=True)\n",
    "\n",
    "    # Drop the extra column 'rounded_score1' if no longer needed\n",
    "    df.drop('rounded_score1', axis=1, inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_location_score2_using_mean_score1 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_prop_review_score(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean of 'prop_review_score' for each rounded integer value\n",
    "    mean_review_score_for_starrating = df.groupby('prop_starrating')['prop_review_score'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_review_score' based on rounded integer values\n",
    "    df['prop_review_score'].fillna(df['prop_starrating'].map(mean_review_score_for_starrating), inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_review_score runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def impute_prop_starrating(df: pd.DataFrame):\n",
    "\n",
    "\n",
    "# Calculate the mean distance per hotel and impute the NaN values with the mean distance\n",
    "def impute_orig_destination_distance(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean distance per hotel\n",
    "    mean_distance_per_hotel = df.groupby('prop_id')['orig_destination_distance'].mean()\n",
    "    \n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['prop_id'].map(mean_distance_per_hotel), inplace=True)\n",
    "\n",
    "    # BUT there are also hotels that contain only NaN values for orig_destination_distance, \n",
    "    # for these we impute it with the mean distance for the country_id\n",
    "    # Use visitor_location_country_id or country_id?\n",
    "\n",
    "    # Calculate the mean distance per country\n",
    "    mean_distance_per_country = df.groupby('visitor_location_country_id')['orig_destination_distance'].mean()\n",
    "\n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['visitor_location_country_id'].map(mean_distance_per_country), inplace=True)\n",
    "    \n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_orig_destination_distance runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_and_transform_query_affinity_score(df : pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['srch_query_affinity_score'] = np.power(2, df['srch_query_affinity_score'])\n",
    "    df['srch_query_affinity_score'].fillna(0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def define_target(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    df['target'] = df['click_bool'] +  df['booking_bool'] * 5\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"define_target runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode(df : pd.DataFrame, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"one_hot_encode runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_id_columns(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.endswith('_id'):\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"delete_id_columns runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_nan_columns(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            #print(col)\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"drop_nan_columns runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_columns_containing_string(df : pd.DataFrame):\n",
    "    matching_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    if matching_columns:\n",
    "        print(\"Columns containing string values:\")\n",
    "        for col in matching_columns:\n",
    "            print(col)\n",
    "\n",
    "\n",
    "def remove_column(df : pd.DataFrame, column_name):\n",
    "    df = df.drop(column_name, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "#rescale all columns to [0,1]\n",
    "def rescaler(df : pd.DataFrame):\n",
    "    for col in df.columns:\n",
    "        # except for the id columns\n",
    "        if not col.endswith('_id'):\n",
    "            df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    #df = remove_column(df, 'date_time')\n",
    "    df = add_nan_column(df, ['prop_review_score', 'srch_query_affinity_score'])\n",
    "    df = add_zero_column(df, ['prop_review_score', 'prop_starrating'])\n",
    "    #df = price_per_night_single_stays(df)\n",
    "    # df = price_per_night_multiple_stays\n",
    "    # df = impute_prop_loc_score2_using_future_score2(df)\n",
    "    df = impute_prop_location_score2_using_mean_score1(df)\n",
    "    df = impute_prop_review_score(df)\n",
    "    df = impute_orig_destination_distance(df)\n",
    "    df = impute_and_transform_query_affinity_score(df)\n",
    "    #df = define_target(df)\n",
    "\n",
    "    # With XGBoost no need to one-hot encode en delete id columns\n",
    "    # df = one_hot_encode(df, ['prop_country_id', 'visitor_location_country_id','prop_id'])\n",
    "    # df = delete_id_columns(df)\n",
    "\n",
    "    df = drop_nan_columns(df)\n",
    "    #df = print_columns_containing_string(df)\n",
    "    #df = rescaler(df)\n",
    "\n",
    "    # --- Save the cleaned data to a csv file ---\n",
    "    df.to_csv('data_cleaned.csv', index=False)\n",
    "    #df.to_csv('clean_0.1_sample.csv', index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('/Users/noahv/Data-Mining-techniques/course_dmt/ass2/datasets/training_set_VU_DM.csv')\n",
    "\n",
    "df = main(df)\n",
    "# n = int(len(df) * 0.1)\n",
    "\n",
    "# first_10_percent = df.head(n)\n",
    "\n",
    "# df = main(first_10_percent)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_nan_column runtime: 0.12 seconds\n",
      "add_zero_column runtime: 0.25 seconds\n",
      "impute_prop_location_score2_using_mean_score1 runtime: 10.45 seconds\n",
      "impute_prop_review_score runtime: 0.64 seconds\n",
      "impute_orig_destination_distance runtime: 1.72 seconds\n",
      "drop_nan_columns runtime: 35.82 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_adults_count</th>\n",
       "      <th>srch_children_count</th>\n",
       "      <th>srch_room_count</th>\n",
       "      <th>srch_saturday_night_bool</th>\n",
       "      <th>srch_query_affinity_score</th>\n",
       "      <th>random_bool</th>\n",
       "      <th>prop_review_score_is_nan</th>\n",
       "      <th>srch_query_affinity_score_is_nan</th>\n",
       "      <th>prop_review_score_is_zero</th>\n",
       "      <th>prop_starrating_is_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>3180</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>5543</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>14142</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.71</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>22393</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>24194</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959178</th>\n",
       "      <td>332787</td>\n",
       "      <td>2013-05-21 11:06:37</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>117</td>\n",
       "      <td>32019</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959179</th>\n",
       "      <td>332787</td>\n",
       "      <td>2013-05-21 11:06:37</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>117</td>\n",
       "      <td>33959</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959180</th>\n",
       "      <td>332787</td>\n",
       "      <td>2013-05-21 11:06:37</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>117</td>\n",
       "      <td>35240</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959181</th>\n",
       "      <td>332787</td>\n",
       "      <td>2013-05-21 11:06:37</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>117</td>\n",
       "      <td>94437</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959182</th>\n",
       "      <td>332787</td>\n",
       "      <td>2013-05-21 11:06:37</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>117</td>\n",
       "      <td>99509</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4959183 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0              1  2013-02-02 15:27:40       24                          216   \n",
       "1              1  2013-02-02 15:27:40       24                          216   \n",
       "2              1  2013-02-02 15:27:40       24                          216   \n",
       "3              1  2013-02-02 15:27:40       24                          216   \n",
       "4              1  2013-02-02 15:27:40       24                          216   \n",
       "...          ...                  ...      ...                          ...   \n",
       "4959178   332787  2013-05-21 11:06:37       24                          216   \n",
       "4959179   332787  2013-05-21 11:06:37       24                          216   \n",
       "4959180   332787  2013-05-21 11:06:37       24                          216   \n",
       "4959181   332787  2013-05-21 11:06:37       24                          216   \n",
       "4959182   332787  2013-05-21 11:06:37       24                          216   \n",
       "\n",
       "         prop_country_id  prop_id  prop_starrating  prop_review_score  \\\n",
       "0                    219     3180                3                4.5   \n",
       "1                    219     5543                3                4.5   \n",
       "2                    219    14142                2                3.5   \n",
       "3                    219    22393                3                4.5   \n",
       "4                    219    24194                3                4.5   \n",
       "...                  ...      ...              ...                ...   \n",
       "4959178              117    32019                4                3.5   \n",
       "4959179              117    33959                4                3.0   \n",
       "4959180              117    35240                4                0.0   \n",
       "4959181              117    94437                4                0.0   \n",
       "4959182              117    99509                4                4.5   \n",
       "\n",
       "         prop_brand_bool  prop_location_score1  ...  srch_adults_count  \\\n",
       "0                      1                  2.94  ...                  2   \n",
       "1                      1                  2.64  ...                  2   \n",
       "2                      1                  2.71  ...                  2   \n",
       "3                      1                  2.40  ...                  2   \n",
       "4                      1                  2.94  ...                  2   \n",
       "...                  ...                   ...  ...                ...   \n",
       "4959178                0                  2.48  ...                  1   \n",
       "4959179                1                  2.20  ...                  1   \n",
       "4959180                0                  1.79  ...                  1   \n",
       "4959181                0                  2.94  ...                  1   \n",
       "4959182                1                  2.08  ...                  1   \n",
       "\n",
       "         srch_children_count  srch_room_count  srch_saturday_night_bool  \\\n",
       "0                          0                1                         0   \n",
       "1                          0                1                         0   \n",
       "2                          0                1                         0   \n",
       "3                          0                1                         0   \n",
       "4                          0                1                         0   \n",
       "...                      ...              ...                       ...   \n",
       "4959178                    0                1                         0   \n",
       "4959179                    0                1                         0   \n",
       "4959180                    0                1                         0   \n",
       "4959181                    0                1                         0   \n",
       "4959182                    0                1                         0   \n",
       "\n",
       "         srch_query_affinity_score  random_bool  prop_review_score_is_nan  \\\n",
       "0                              0.0            0                         0   \n",
       "1                              0.0            0                         0   \n",
       "2                              0.0            0                         0   \n",
       "3                              0.0            0                         0   \n",
       "4                              0.0            0                         0   \n",
       "...                            ...          ...                       ...   \n",
       "4959178                        0.0            0                         0   \n",
       "4959179                        0.0            0                         0   \n",
       "4959180                        0.0            0                         0   \n",
       "4959181                        0.0            0                         0   \n",
       "4959182                        0.0            0                         0   \n",
       "\n",
       "         srch_query_affinity_score_is_nan  prop_review_score_is_zero  \\\n",
       "0                                       1                          0   \n",
       "1                                       1                          0   \n",
       "2                                       1                          0   \n",
       "3                                       1                          0   \n",
       "4                                       1                          0   \n",
       "...                                   ...                        ...   \n",
       "4959178                                 1                          0   \n",
       "4959179                                 1                          0   \n",
       "4959180                                 1                          1   \n",
       "4959181                                 1                          1   \n",
       "4959182                                 1                          0   \n",
       "\n",
       "         prop_starrating_is_zero  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "4959178                        0  \n",
       "4959179                        0  \n",
       "4959180                        0  \n",
       "4959181                        0  \n",
       "4959182                        0  \n",
       "\n",
       "[4959183 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_column(df : pd.DataFrame, column_name):\n",
    "    df = df.drop(column_name, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_nan_column(df : pd.DataFrame, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_nan'] = df[col].isna().astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_nan_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_zero_column(df : pd.DataFrame, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df[str(col) + '_is_zero'] = df[col].eq(0).astype(np.int8)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"add_zero_column runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Calculates the price per night where we know the length of stay is equal to 1 for each prop_id\n",
    "def price_per_night_single_stays(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mask = df['srch_length_of_stay'] == 1\n",
    "    df['mean_price_per_night'] = df.groupby('prop_id')['price_usd'].transform(lambda x: x[mask].mean())\n",
    "    return df\n",
    "\n",
    "\n",
    "# def price_per_night_multiple_stays\n",
    "\n",
    "\n",
    "# Function to impute the prop_location_score2 values that are NaN based on the prop_location_score2 values of the same prop_id\n",
    "def impute_prop_loc_score2_using_future_score2(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Retrieve the prop_ids that have a change in prop_location_score2 from NaN to a float over time\n",
    "    has_change_over_time = df.groupby('prop_id')['prop_location_score2'].apply(lambda x: x.diff().notna().any())\n",
    "    prop_ids_change = has_change_over_time[has_change_over_time == True].index\n",
    "\n",
    "    # For each prop_id that has a change in prop_location_score2 from NaN to a float over time, impute the NaN values with the first non-NaN value\n",
    "    for prop_id in prop_ids_change:\n",
    "        mask = (df['prop_id'] == prop_id) & (df['prop_location_score2'].isnull())\n",
    "        non_nan_value = df.loc[(df['prop_id'] == prop_id) & (df['prop_location_score2'].notna()), 'prop_location_score2'].values[0]\n",
    "        df.loc[mask, 'prop_location_score2'] = non_nan_value\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_loc_score2_using_future_score2 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Impute remaning NaN values using the mean prop_locatioin_score2 values for each prop_location_score1 value\n",
    "def impute_prop_location_score2_using_mean_score1(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create an extra column with rounded 'prop_location_score1'\n",
    "    df['rounded_score1'] = df['prop_location_score1'].round()\n",
    "\n",
    "    # Calculate the mean of 'prop_location_score2' for each rounded integer value\n",
    "    mean_score2_by_rounded = df.groupby('rounded_score1')['prop_location_score2'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_location_score2' based on rounded integer values\n",
    "    df['prop_location_score2'].fillna(df['rounded_score1'].map(mean_score2_by_rounded), inplace=True)\n",
    "\n",
    "    # Drop the extra column 'rounded_score1' if no longer needed\n",
    "    df.drop('rounded_score1', axis=1, inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_location_score2_using_mean_score1 runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_prop_review_score(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean of 'prop_review_score' for each rounded integer value\n",
    "    mean_review_score_for_starrating = df.groupby('prop_starrating')['prop_review_score'].mean()\n",
    "\n",
    "    # Impute missing values of 'prop_review_score' based on rounded integer values\n",
    "    df['prop_review_score'].fillna(df['prop_starrating'].map(mean_review_score_for_starrating), inplace=True)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_prop_review_score runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#def impute_prop_starrating(df: pd.DataFrame):\n",
    "\n",
    "#def impute_query_affinity_score(df: pd.DataFrame):\n",
    "\n",
    "\n",
    "# Calculate the mean distance per hotel and impute the NaN values with the mean distance\n",
    "def impute_orig_destination_distance(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Calculate the mean distance per hotel\n",
    "    mean_distance_per_hotel = df.groupby('prop_id')['orig_destination_distance'].mean()\n",
    "    \n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['prop_id'].map(mean_distance_per_hotel), inplace=True)\n",
    "\n",
    "    # BUT there are also hotels that contain only NaN values for orig_destination_distance, \n",
    "    # for these we impute it with the mean distance for the country_id\n",
    "    # Use visitor_location_country_id or country_id?\n",
    "\n",
    "    # Calculate the mean distance per country\n",
    "    mean_distance_per_country = df.groupby('visitor_location_country_id')['orig_destination_distance'].mean()\n",
    "\n",
    "    # Impute the NaN values with the mean distance\n",
    "    df['orig_destination_distance'].fillna(df['visitor_location_country_id'].map(mean_distance_per_country), inplace=True)\n",
    "    \n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"impute_orig_destination_distance runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_and_transform_query_affinity_score(df : pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['srch_query_affinity_score'] = np.power(2, df['srch_query_affinity_score'])\n",
    "    df['srch_query_affinity_score'].fillna(0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def define_target(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    df['target'] = df['click_bool'] +  df['booking_bool'] * 5\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"define_target runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode(df : pd.DataFrame, cols):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in cols:\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"one_hot_encode runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_id_columns(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.endswith('_id'):\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"delete_id_columns runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_nan_columns(df: pd.DataFrame)-> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            #print(col)\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    # Print the runtime\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"drop_nan_columns runtime: %.2f seconds\" % elapsed_time)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_columns_containing_string(df : pd.DataFrame):\n",
    "    matching_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    if matching_columns:\n",
    "        print(\"Columns containing string values:\")\n",
    "        for col in matching_columns:\n",
    "            print(col)\n",
    "\n",
    "\n",
    "def remove_column(df : pd.DataFrame, column_name):\n",
    "    df = df.drop(column_name, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "#rescale all columns to [0,1]\n",
    "def rescaler(df : pd.DataFrame):\n",
    "    for col in df.columns:\n",
    "        # except for the id columns\n",
    "        if not col.endswith('_id'):\n",
    "            df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    return df\n",
    "\n",
    "\n",
    "def main(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    #df = remove_column(df, 'date_time')\n",
    "    df = add_nan_column(df, ['prop_review_score', 'srch_query_affinity_score'])\n",
    "    df = add_zero_column(df, ['prop_review_score', 'prop_starrating'])\n",
    "    #df = price_per_night_single_stays(df)\n",
    "    # df = price_per_night_multiple_stays\n",
    "    # df = impute_prop_loc_score2_using_future_score2(df)\n",
    "    df = impute_prop_location_score2_using_mean_score1(df)\n",
    "    df = impute_prop_review_score(df)\n",
    "    df = impute_orig_destination_distance(df)\n",
    "    df = impute_and_transform_query_affinity_score(df)\n",
    "\n",
    "    # Cannot add target to the test set\n",
    "    #df = define_target(df)\n",
    "\n",
    "    # With XGBoost no need to one-hot encode en delete id columns\n",
    "    # df = one_hot_encode(df, ['prop_country_id', 'visitor_location_country_id','prop_id'])\n",
    "    # df = delete_id_columns(df)\n",
    "\n",
    "    df = drop_nan_columns(df)\n",
    "    #df = print_columns_containing_string(df)\n",
    "    #df = rescaler(df)\n",
    "    df.to_csv('test_data_cleaned.csv', index=False)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('/Users/noahv/Data-Mining-techniques/course_dmt/ass2/datasets/test_set_VU_DM.csv')\n",
    "df = main(df)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
